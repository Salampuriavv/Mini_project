{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 302713,
          "sourceType": "datasetVersion",
          "datasetId": 125828
        }
      ],
      "dockerImageVersionId": 30646,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T08:27:45.039645Z",
          "iopub.execute_input": "2024-02-19T08:27:45.040086Z",
          "iopub.status.idle": "2024-02-19T08:27:45.044791Z",
          "shell.execute_reply.started": "2024-02-19T08:27:45.040055Z",
          "shell.execute_reply": "2024-02-19T08:27:45.043864Z"
        },
        "trusted": true,
        "id": "mIIASRm25lFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"overview-of-recordings.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T08:27:45.04683Z",
          "iopub.execute_input": "2024-02-19T08:27:45.047403Z",
          "iopub.status.idle": "2024-02-19T08:27:45.119282Z",
          "shell.execute_reply.started": "2024-02-19T08:27:45.047377Z",
          "shell.execute_reply": "2024-02-19T08:27:45.118428Z"
        },
        "trusted": true,
        "id": "mhqWJslI5lFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Check the distribution of phrases and prompts\n",
        "print(\"Unique phrases:\", df['phrase'].nunique())\n",
        "print(\"Unique prompts:\", df['prompt'].nunique())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T08:54:40.879537Z",
          "iopub.execute_input": "2024-02-19T08:54:40.88019Z",
          "iopub.status.idle": "2024-02-19T08:54:40.896677Z",
          "shell.execute_reply.started": "2024-02-19T08:54:40.880156Z",
          "shell.execute_reply": "2024-02-19T08:54:40.895731Z"
        },
        "trusted": true,
        "id": "6_x8R4pv5lFc",
        "outputId": "f88b9240-ff76-4f6d-c2f4-0f0cf0aa30e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "   audio_clipping  audio_clipping:confidence background_noise_audible  \\\n0     no_clipping                     1.0000              light_noise   \n1  light_clipping                     0.6803                 no_noise   \n2     no_clipping                     1.0000                 no_noise   \n3     no_clipping                     1.0000              light_noise   \n4     no_clipping                     1.0000                 no_noise   \n\n   background_noise_audible:confidence  overall_quality_of_the_audio  \\\n0                               1.0000                          3.33   \n1                               0.6803                          3.33   \n2                               0.6655                          3.33   \n3                               1.0000                          3.33   \n4                               1.0000                          4.67   \n\n     quiet_speaker  quiet_speaker:confidence  speaker_id  \\\n0  audible_speaker                       1.0    43453425   \n1  audible_speaker                       1.0    43719934   \n2  audible_speaker                       1.0    43719934   \n3  audible_speaker                       1.0    31349958   \n4  audible_speaker                       1.0    43719934   \n\n                                       file_download  \\\n0  https://ml.sandbox.cf3.us/cgi-bin/index.cgi?do...   \n1  https://ml.sandbox.cf3.us/cgi-bin/index.cgi?do...   \n2  https://ml.sandbox.cf3.us/cgi-bin/index.cgi?do...   \n3  https://ml.sandbox.cf3.us/cgi-bin/index.cgi?do...   \n4  https://ml.sandbox.cf3.us/cgi-bin/index.cgi?do...   \n\n                       file_name  \\\n0  1249120_43453425_58166571.wav   \n1  1249120_43719934_43347848.wav   \n2  1249120_43719934_53187202.wav   \n3  1249120_31349958_55816195.wav   \n4  1249120_43719934_82524191.wav   \n\n                                              phrase            prompt  \\\n0                    When I remember her I feel down    Emotional pain   \n1  When I carry heavy things I feel like breaking...  Hair falling out   \n2          there is too much pain when i move my arm       Heart hurts   \n3  My son had his lip pierced and it is swollen a...    Infected wound   \n4             My muscles in my lower back are aching    Infected wound   \n\n   writer_id  \n0   21665495  \n1   44088126  \n2   44292353  \n3   43755034  \n4   21665495  \nUnique phrases: 706\nUnique prompts: 25\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T09:16:32.668173Z",
          "iopub.execute_input": "2024-02-19T09:16:32.668573Z",
          "iopub.status.idle": "2024-02-19T09:17:05.403661Z",
          "shell.execute_reply.started": "2024-02-19T09:16:32.668541Z",
          "shell.execute_reply": "2024-02-19T09:17:05.402561Z"
        },
        "trusted": true,
        "id": "U21UepYT5lFd",
        "outputId": "ee226ce0-f452-4b13-8f58-ce41e2911139"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize tokens\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    # Join tokens back into a string\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'phrase' and 'prompt' columns\n",
        "df['clean_phrase'] = df['phrase'].apply(preprocess_text)\n",
        "df['clean_prompt'] = df['prompt'].apply(preprocess_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T09:17:05.405638Z",
          "iopub.execute_input": "2024-02-19T09:17:05.405979Z"
        },
        "trusted": true,
        "id": "BJZAgaW25lFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_text = df[['phrase', 'prompt']]\n",
        "df_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T08:27:45.158171Z",
          "iopub.execute_input": "2024-02-19T08:27:45.158439Z",
          "iopub.status.idle": "2024-02-19T08:27:45.17567Z",
          "shell.execute_reply.started": "2024-02-19T08:27:45.158417Z",
          "shell.execute_reply": "2024-02-19T08:27:45.174913Z"
        },
        "trusted": true,
        "id": "C30lSF4W5lFe",
        "outputId": "e7c6f331-6cee-46bd-ad04-f57cf757a10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                 phrase            prompt\n0                       When I remember her I feel down    Emotional pain\n1     When I carry heavy things I feel like breaking...  Hair falling out\n2             there is too much pain when i move my arm       Heart hurts\n3     My son had his lip pierced and it is swollen a...    Infected wound\n4                My muscles in my lower back are aching    Infected wound\n...                                                 ...               ...\n6656  I feel a burning sensation in my guts about 2 ...      Stomach ache\n6657     I have a split on my thumb that will not heal.        Open wound\n6658                I feel a lot of pain in the joints.        Joint pain\n6659        The area around my heart doesn't feel good.       Heart hurts\n6660                  I complain alot with skin allergy        Skin issue\n\n[6661 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phrase</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>When I remember her I feel down</td>\n      <td>Emotional pain</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I carry heavy things I feel like breaking...</td>\n      <td>Hair falling out</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>there is too much pain when i move my arm</td>\n      <td>Heart hurts</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>My son had his lip pierced and it is swollen a...</td>\n      <td>Infected wound</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>My muscles in my lower back are aching</td>\n      <td>Infected wound</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6656</th>\n      <td>I feel a burning sensation in my guts about 2 ...</td>\n      <td>Stomach ache</td>\n    </tr>\n    <tr>\n      <th>6657</th>\n      <td>I have a split on my thumb that will not heal.</td>\n      <td>Open wound</td>\n    </tr>\n    <tr>\n      <th>6658</th>\n      <td>I feel a lot of pain in the joints.</td>\n      <td>Joint pain</td>\n    </tr>\n    <tr>\n      <th>6659</th>\n      <td>The area around my heart doesn't feel good.</td>\n      <td>Heart hurts</td>\n    </tr>\n    <tr>\n      <th>6660</th>\n      <td>I complain alot with skin allergy</td>\n      <td>Skin issue</td>\n    </tr>\n  </tbody>\n</table>\n<p>6661 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example dataset (replace it with your actual dataset)\n",
        "phrases = df['phrase'].tolist()\n",
        "prompts = df['prompt'].tolist()\n",
        "\n",
        "# Tokenize text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(phrases)\n",
        "X = tokenizer.texts_to_sequences(phrases)\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max([len(seq) for seq in X])\n",
        "X_padded = pad_sequences(X, maxlen=max_length, padding='post')\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "label_to_index = {label: i for i, label in enumerate(set(prompts))}\n",
        "y = [label_to_index[label] for label in prompts]\n",
        "y_one_hot = np.zeros((len(y), len(label_to_index)))\n",
        "for i, label_index in enumerate(y):\n",
        "    y_one_hot[i, label_index] = 1\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model architecture\n",
        "embedding_dim = 100\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dense(units=len(label_to_index), activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T08:27:45.176627Z",
          "iopub.execute_input": "2024-02-19T08:27:45.176928Z",
          "iopub.status.idle": "2024-02-19T08:28:11.894356Z",
          "shell.execute_reply.started": "2024-02-19T08:27:45.176906Z",
          "shell.execute_reply": "2024-02-19T08:28:11.893567Z"
        },
        "trusted": true,
        "id": "S2LmYlKI5lFe",
        "outputId": "da44fa95-5916-4f6c-a70f-43d40df29511"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1708331269.262323     100 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "134/134 [==============================] - 13s 77ms/step - loss: 3.0687 - accuracy: 0.0774 - val_loss: 2.4544 - val_accuracy: 0.2083\nEpoch 2/10\n134/134 [==============================] - 2s 16ms/step - loss: 1.9177 - accuracy: 0.3151 - val_loss: 1.5308 - val_accuracy: 0.4174\nEpoch 3/10\n134/134 [==============================] - 1s 10ms/step - loss: 1.2370 - accuracy: 0.5209 - val_loss: 1.1429 - val_accuracy: 0.5910\nEpoch 4/10\n134/134 [==============================] - 1s 10ms/step - loss: 0.8010 - accuracy: 0.7037 - val_loss: 0.7875 - val_accuracy: 0.6923\nEpoch 5/10\n134/134 [==============================] - 1s 10ms/step - loss: 0.5088 - accuracy: 0.8351 - val_loss: 0.5332 - val_accuracy: 0.8321\nEpoch 6/10\n134/134 [==============================] - 1s 8ms/step - loss: 0.4582 - accuracy: 0.8618 - val_loss: 0.3263 - val_accuracy: 0.9268\nEpoch 7/10\n134/134 [==============================] - 1s 9ms/step - loss: 0.1663 - accuracy: 0.9629 - val_loss: 0.1354 - val_accuracy: 0.9756\nEpoch 8/10\n134/134 [==============================] - 1s 9ms/step - loss: 0.2145 - accuracy: 0.9406 - val_loss: 0.3991 - val_accuracy: 0.9062\nEpoch 9/10\n134/134 [==============================] - 1s 6ms/step - loss: 0.1717 - accuracy: 0.9575 - val_loss: 0.1186 - val_accuracy: 0.9747\nEpoch 10/10\n134/134 [==============================] - 1s 10ms/step - loss: 0.0462 - accuracy: 0.9930 - val_loss: 0.0738 - val_accuracy: 0.9878\n42/42 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9940\nTest Loss: 0.047696303576231, Test Accuracy: 0.9939985275268555\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}